import streamlit as st
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.chains.question_answering import load_qa_chain

from vectorstore_utils import load_or_build_vectorstore

st.set_page_config(page_title="ðŸ“˜ Ask the Textbook", page_icon="ðŸ“˜")

st.title("ðŸ“˜ Ask the Textbook")
st.markdown("Ask anything about Tony Bates' *Teaching in a Digital Age*")

query = st.text_input("ðŸ’¬ Ask a question:")

vectorstore = load_or_build_vectorstore()
system_prompt = load_system_prompt()

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever(),
    chain_type="stuff",
    chain_type_kwargs={"prompt": system_prompt}
)

if query:
    result = qa_chain.run(query)
    st.write(result)
